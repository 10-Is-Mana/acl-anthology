<volume id='Q17'>
  <paper id='1000'>
    <title>Transactions of the Association of Computational Linguistics – Volume 5, Issue 1</title>
  </paper>

  <paper id='1001'>
    <title>Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Labels</title>
    <author><first>Alison</first><last>Smith</last></author>
    <author><first>Tak Yeon</first><last>Lee</last></author>
    <author><first>Forough</first><last>Poursabzi-Sangdeh</last></author>
    <author><first>Jordan</first><last>Boyd-Graber</last></author>
    <author><first>Niklas</first><last>Elmqvist</last></author>
    <author><first>Leah</first><last>Findlater</last></author>
    <year>2017</year>
    <abstract>Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes.  However, promoting end-user understanding of topics remains an open research problem.  We compare labels generated by users given four topic visualization techniques—word lists, word lists with bars, word clouds, and network graphs—against each other and against automatically generated labels.  Our basis of comparison is participant ratings of how well labels describe documents from the topic. Our study has two phases: a labeling phase where participants label visualized topics and a validation phase where different participants select which labels best describe the topics' documents.  Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure.  Automatic labels lag behind user-created labels, but our dataset of manually labeled topics highlights linguistic patterns (e.g., hypernyms, phrases) that can be used to improve automatic topic labeling algorithms.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/887/222</href>
    <pages>1--15</pages>
    <url>http://www.aclweb.org/anthology/Q17-1001</url>
  </paper>

  <paper id='1002'>
    <title>Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns</title>
    <author><first>Andrew J.</first><last>Anderson</last></author>
    <author><first>Douwe</first><last>Kiela</last></author>
    <author><first>Stephen</first><last>Clark</last></author>
    <author><first>Massimo</first><last>Poesio</last></author>
    <year>2017</year>
    <abstract>Important advances have recently been made using computational semantic models to decode brain activity patterns associated with concepts; however, this work has almost exclusively focused on concrete nouns. How well these models extend to decoding abstract nouns is largely unknown. We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns. One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia. The second is visually grounded, using deep convolutional neural networks trained on Google Images. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically. Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns; however, accuracy is significantly greater using the text-based models for the most abstract nouns. More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/879/223</href>
    <pages>17--30</pages>
    <url>http://www.aclweb.org/anthology/Q17-1002</url>
  </paper>

  <paper id='1003'>
    <title>Modelling Semantic Expectation: Using Script Knowledge for Referent Prediction</title>
    <author><first>Ashutosh</first><last>Modi</last></author>
    <author><first>Ivan</first><last>Titov</last></author>
    <author><first>Vera</first><last>Demberg</last></author>
    <author><first>Asad</first><last>Sayeed</last></author>
    <author><first>Manfred</first><last>Pinkal</last></author>
    <year>2017</year>
    <abstract>Recent research in psycholinguistics has provided increasing evidence that humans predict upcoming content. Prediction also affects perception and might be a key to robustness in human language processing. In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. We find that script knowledge significantly improves model estimates of human predictions. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/968/224</href>
    <pages>31--44</pages>
    <url>http://www.aclweb.org/anthology/Q17-1003</url>
  </paper>

  <paper id='1004'>
    <title>Shift-Reduce Constituent Parsing with Neural Lookahead Features</title>
    <author><first>Jiangming</first><last>Liu</last></author>
    <author><first>Yue</first><last>Zhang</last></author>
    <year>2017</year>
    <abstract>Transition-based models can be fast and accurate for constituent parsing. Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents. On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing. To address this limitation, we leverage a fast neural model to extract lookahead features. In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends. The results are then passed to a strong transition-based constituent parser as lookahead features. The resulting parser gives 1.3% absolute improvement in WSJ and 2.3% in CTB compared to the baseline, giving the highest reported accuracies for fully-supervised parsing.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/927/225</href>
    <pages>45--58</pages>
    <url>http://www.aclweb.org/anthology/Q17-1004</url>
  </paper>

  <paper id='1005'>
    <title>A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit</title>
    <author><first>Yin-Wen</first><last>Chang</last></author>
    <author><first>Michael</first><last>Collins</last></author>
    <year>2017</year>
    <abstract>Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the traveling salesman problem (Knight, 1999). In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation. However, the impact on complexity after imposing such a constraint is not well studied. In this paper, we describe a dynamic programming algorithm for phrase-based decoding with a fixed distortion limit. The runtime of the algorithm is O(nd!lh^{d+1}) where n is the sentence length, d is the distortion limit, l is a bound on the number of phrases starting at any position in the sentence, and h is related to the maximum number of target language translations for any source word. The algorithm makes use of a novel representation that gives a new perspective on decoding of phrase-based models.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1020/226</href>
    <pages>59--71</pages>
    <url>http://www.aclweb.org/anthology/Q17-1005</url>
  </paper>

  <paper id='1006'>
    <title>A Generative Model of Phonotactics</title>
    <author><first>Richard</first><last>Futrell</last></author>
    <author><first>Adam</first><last>Albright</last></author>
    <author><first>Peter</first><last>Graff</last></author>
    <author><first>Timothy J.</first><last>O'Donnell</last></author>
    <year>2017</year>
    <abstract>We present a probabilistic model of phonotactics, the set of well-formed phoneme sequences in a language. Unlike most computational models of phonotactics (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), we take a fully generative approach, modeling a process where forms are built up out of subparts by phonologically-informed structure building operations. We learn an inventory of subparts by applying stochastic memoization (Johnson et al., 2006; Goodman et al., 2008) to a generative process for phonemes structured as an and-or graph, based on concepts of feature hierarchy from generative phonology (Clements, 1985; Dresher, 2009). Subparts are combined in a way that allows tier-based feature interactions. We evaluate our models’ ability to capture phonotactic distributions in the lexicons of 14 languages drawn from the WOLEX corpus (Graff, 2012). Our full model robustly assigns higher probabilities to held-out forms than a sophisticated N-gram model for all languages. We also present novel analyses that probe model behavior in more detail.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/971/227</href>
    <pages>73--86</pages>
    <url>http://www.aclweb.org/anthology/Q17-1006</url>
  </paper>

  <paper id='1007'>
    <title>Context Gates for Neural Machine Translation</title>
    <author><first>Zhaopeng</first><last>Tu</last></author>
    <author><first>Yang</first><last>Liu</last></author>
    <author><first>Zhengdong</first><last>Lu</last></author>
    <author><first>Xiaohua</first><last>Liu</last></author>
    <author><first>Hang</first><last>Li</last></author>
    <year>2017</year>
    <abstract>In neural machine translation (NMT), generation of a target word depends on both source and target contexts. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. In this way, we can enhance both the adequacy and fluency of NMT with more careful control of the information flow from contexts. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/948/228</href>
    <pages>87-99</pages>
    <url>http://www.aclweb.org/anthology/Q17-1007</url>
  </paper>

  <paper id='1008'>
    <title>Cross-Sentence N-ary Relation Extraction with Graph LSTMs</title>
    <author><first>Nanyun</first><last>Peng</last></author>
    <author><first>Hoifung</first><last>Poon</last></author>
    <author><first>Chris</first><last>Quirk</last></author>
    <author><first>Kristina</first><last>Toutanova</last></author>
    <author><first>Wen-tau</first><last>Yih</last></author>
    <year>2017</year>
    <abstract>Past work in relation extraction focuses on binary relations in single sentences. Recent NLP inroads in high-valued domains have kindled strong interest in the more general setting of extracting n-ary relations that span multiple sentences. In this paper, we explore a general relation extraction framework based on graph long short-term memory (graph LSTM), which can be easily extended to cross-sentence n-ary relation extraction. The graph formulation provides a unifying way to explore different LSTM approaches and incorporate various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations. A robust contextual representation is learned for the entities, which serves as input to the relation classifier, making it easy for scaling to arbitrary relation arity n, as well as for multi-task learning with related relations. We evaluated this framework in two important domains in precision medicine and demonstrated its effectiveness with both supervised learning and distant supervision. Cross-sentence extraction produced far more knowledge, and multi-task learning significantly improved extraction accuracy. A thorough analysis comparing various LSTM approaches yielded interesting insight on how linguistic analysis impacts the performance.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1028/229</href>
    <pages>101--115</pages>
    <url>http://www.aclweb.org/anthology/Q17-1008</url>
  </paper>

  <paper id='1009'>
    <title>Automatically Tagging Constructions of Causation and Their Slot-Fillers</title>
    <author><first>Jesse</first><last>Dunietz</last></author>
    <author><first>Lori</first><last>Levin</last></author>
    <author><first>Jaime</first><last>Carbonell</last></author>
    <year>2017</year>
    <abstract>This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case. Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations that causation can take on. We therefore base our approach on the concept of constructions from the linguistic paradigm known as construction grammar (CxG). In CxG, a construction is a form/function pairing that can rely on arbitrary linguistic and semantic features. Rather than codifying all aspects of each construction’s form, as some attempts to employ CxG in NLP have done, we propose methods that offload that problem to machine learning. We describe two supervised approaches for tagging causal constructions and their arguments. Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions. Our results show that these approaches are promising: they significantly outperform naive baselines for both construction recognition and cause and effect head matches.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/</href>
    <pages>117--133</pages>
    <url>http://www.aclweb.org/anthology/Q17-1009</url>
  </paper>

  <paper id='1010'>
    <title>Enriching Word Vectors with Subword Information</title>
    <author><first>Piotr</first><last>Bojanowski</last></author>
    <author><first>Edouard</first><last>Grave</last></author>
    <author><first>Armand</first><last>Joulin</last></author>
    <author><first>Tomas</first><last>Mikolov</last></author>
    <year>2017</year>
    <abstract>Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models to learn such representations  ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram, words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/</href>
    <pages>135--146</pages>
    <url>http://www.aclweb.org/anthology/Q17-1010</url>
  </paper>

  <paper id='1011'>
    <title>Fine-Grained Prediction of Syntactic Typology: Discovering Latent Structure with Supervised Learning</title>
    <author><first>Dingquan</first><last>Wang</last></author>
    <author><first>Jason</first><last>Eisner</last></author>
    <year>2017</year>
    <abstract>We show how to predict the basic word-order facts of a novel language given only a corpus of part-of-speech (POS) sequences. We predict how often direct objects follow their verbs, how often adjectives follow their nouns, and in general the directionalities of all dependency relations. Such typological properties could be helpful in grammar induction. While such a problem is usually regarded as unsupervised learning, our innovation is to treat it as supervised learning, using a large collection of realistic synthetic languages as training data. The supervised learner must identify surface features of a language’s POS sequence (hand-engineered or neural features) that correlate with the language’s deeper structure (latent trees). In the experiment, we show: 1) Given a small set of real languages, it helps to add many synthetic languages to the training data. 2) Our system is robust even when the POS sequences include noise. 3) Our system on this task outperforms a grammar induction baseline by a large margin.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1060/232</href>
    <pages>147--161</pages>
    <url>http://www.aclweb.org/anthology/Q17-1011</url>
  </paper>

   <paper id='1012'>
    <title>Head-Lexicalized Bidirectional Tree LSTMs</title>
    <author><first>Zhiyang</first><last>Teng</last></author>
    <author><first>Yue</first><last>Zhang</last></author>
    <year>2017</year>
    <abstract>Sequential LSTMs have been extended to model tree structures, giving competitive results for a number of tasks. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. This is different from sequential LSTMs, which contain references to input words for each node. In this paper, we propose a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node.  In addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTMs in structure. Experiments show that both extensions give better representations of tree structures. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/925/233</href>
    <pages>163--177</pages>
    <url>http://www.aclweb.org/anthology/Q17-1012</url>
  </paper>

  <paper id='1013'>
    <title>Nonparametric Bayesian Semi-supervised Word Segmentation</title>
    <author><first>Ryo</first><last>Fujii</last></author>
    <author><first>Ryo</first><last>Domoto</last></author>
    <author><first>Daichi</first><last>Mochihashi</last></author>
    <year>2017</year>
    <abstract>This paper presents a novel hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods.  Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new "words", and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services.Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001)) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)) with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki et al. (2008)).  We confirmed that it can appropriately segment non-standard texts like those in Twitter and Weibo and has nearly state-of-the-art accuracy on standard datasets in Japanese, Chinese, and Thai.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1037/235</href>
    <pages>179--189</pages>
    <url>http://www.aclweb.org/anthology/Q17-1013</url>
  </paper>

  <paper id='1014'>
    <title>Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora</title>
    <author><first>Jooyeon</first><last>Kim</last></author>
    <author><first>Dongwoo</first><last>Kim</last></author>
    <author><first>Alice</first><last>Oh</last></author>
    <year>2017</year>
    <abstract>Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult. We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics. We present Latent Topical-Authority Indexing (LTAI) for jointly modeling the topics, citations, and topical authority in a corpus of academic papers. Compared to previous models, LTAI differs in two main aspects. First, it explicitly models the generative process of the citations, rather than treating the citations as given. Second, it models each author's influence on citations of a paper based on the topics of the cited papers, as well as the citing papers. We fit LTAI to four academic corpora: CORA, Arxiv Physics, PNAS, and Citeseer. We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation topic model. The results show that LTAI achieves improved accuracy over other similar models when predicting words, citations and authors of publications.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1061/236</href>
    <pages>191--204</pages>
    <url>http://www.aclweb.org/anthology/Q17-1014</url>
  </paper>

  <paper id='1015'>
    <title>Pushing the Limits of Translation Quality Estimation</title>
    <author><first>André F.T.</first><last>Martins</last></author>
    <author><first>Marcin</first><last>Junczys-Dowmunt</last></author>
    <author><first>Fabio N.</first><last>Kepler</last></author>
    <author><first>Ramón</first><last>Astudillo</last></author>
    <author><first>Chris</first><last>Hokamp</last></author>
    <author><first>Roman</first><last>Grundkiewicz</last></author>
    <year>2017</year>
    <abstract>Translation quality estimation is a task of growing importance in NLP, due to its potential to reduce post-editing human effort in disruptive ways. However, this potential is currently limited by the relatively low accuracy of existing systems. In this paper, we achieve remarkable improvements by exploiting synergies between the related tasks of word-level quality estimation and automatic post-editing. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system. Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16: a word-level F 1 MULT score of 57.47% (an absolute gain of +7.95% over the current state of the art), and a Pearson correlation score of 65.56% for sentence-level HTER prediction (an absolute gain of +13.36%).</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1113/237</href>
    <pages>205--218</pages>
    <url>http://www.aclweb.org/anthology/Q17-1015</url>
  </paper>

  <paper id='1016'>
    <title>Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes</title>
    <author><first>Lu</first><last>Wang</last></author>
    <author><first>Nick</first><last>Beauchamp</last></author>
    <author><first>Sarah</first><last>Shugars</last></author>
    <author><first>Kechen</first><last>Qin</last></author>
    <year>2017</year>
    <abstract>Debate and deliberation play essential roles in politics and government, but most models presume that debates are won mainly via superior style or agenda control. Ideally, however, debates would be won on the merits, as a function of which side has the stronger arguments. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two. Using a dataset of 118 Oxford-style debates, our model's combination of content (as latent topics) and style (as linguistic features) allows us to predict audience-adjudicated winners with 74% accuracy, significantly outperforming linguistic features alone (66%). Our model finds that winning sides employ stronger arguments, and allows us to identify the linguistic features associated with strong or weak arguments.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1009/239</href>
    <pages>219--232</pages>
    <url>http://www.aclweb.org/anthology/Q17-1016</url>
  </paper>

  <paper id='1017'>
    <title>Domain-Targeted, High Precision Knowledge Extraction</title>
    <author><first>Bhavana Dalvi</first><last>Mishra</last></author>
    <author><first> Niket</first><last>Tandon</last></author>
    <author><first>Peter</first><last>Clark</last></author>
    <year>2017</year>
    <abstract>Our goal is to construct a domain-targeted, high precision knowledge base (KB), containing general (subject,predicate,object) statements about the world, in support of a downstream question-answering (QA) application. Despite recent advances in information extraction (IE) techniques, no suitable resource for our task already exists; existing resources are either too noisy, too named-entity centric, or too incomplete, and typically have not been constructed with a clear scope or purpose. To address these, we have created a domain-targeted, high precision knowledge extraction pipeline, leveraging Open IE, crowdsourcing, and a novel canonical schema learning algorithm (called CASI), that produces high precision knowledge targeted to a particular domain - in our case, elementary science. To measure the KB’s coverage of the target domain’s knowledge (it’s "comprehensiveness" with respect to science) we measure recall with respect to an independent corpus of domain text, and show that our pipeline produces output with over 80% precision and 23% recall with respect to that target, a substantially higher coverage of tuple-expressible science knowledge than other comparable resources. We have made the KB publicly available at http://data.allenai.org/tuple-kb.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1064/242</href>
    <pages>233--246</pages>
    <url>http://www.aclweb.org/anthology/Q17-1017</url>
  </paper>

  <paper id='1018'>
    <title>Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling</title>
    <author><first>Gábor</first><last>Berend</last></author>
    <year>2017</year>
    <abstract>In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages. Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks. The proposed model has favorable generalization properties as it retains over 89.8% of its average POS tagging accuracy when trained at 1.2% of the total available training data, i.e. 150 sentences per language.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1063/241</href>
    <pages>247--261</pages>
    <url>http://www.aclweb.org/anthology/Q17-1018</url>
  </paper>

  <paper id='1019'>
    <title>Learning to Prune: Exploring the Frontier of Fast and Accurate Parsing</title>
    <author><first>Tim</first><last>Vieira</last></author>
    <author><first> Jason</first><last>Eisner</last></author>
    <year>2017</year>
    <abstract>Pruning hypotheses during dynamic programming is commonly used to speed up inference in settings such as parsing.  Unlike prior work, we train a pruning policy under an objective that measures end-to-end performance: we search for a fast and accurate policy. This poses a difficult machine learning problem, which we tackle with the LOLS algorithm.  LOLS training must continually compute the effects of changing pruning decisions: we show how to make this efficient in the constituency parsing setting, via dynamic programming and change propagation algorithms.  We find that optimizing end-to-end performance in this way leads to a better Pareto frontier---i.e., parsers which are more accurate for a given runtime.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/924/243</href>
    <pages>263--278</pages>
    <url>http://www.aclweb.org/anthology/Q17-1019</url>
  </paper>

  <paper id='1020'>
    <title>Cross-Lingual Syntactic Transfer with Limited Resources</title>
    <author><first>Mohammad Sadegh</first><last>Rasooli</last></author>
    <author><first>Michael</first><last>Collins</last></author>
    <year>2017</year>
    <abstract>We describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available. The method makes use of three steps: 1) a method for deriving cross-lingual word clusters, which can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets from the Universal Dependencies corpora.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/922/244</href>
    <pages>279--293</pages>
    <url>http://www.aclweb.org/anthology/Q17-1020</url>
  </paper>

  <paper id='1021'>
    <title>Overcoming Language Variation in Sentiment Analysis with Social Attention</title>
    <author><first>Yi</first><last>Yang</last></author>
    <author><first>Jacob</first><last>Eisenstein</last></author>
    <year>2017</year>
    <abstract>{Variation in language is ubiquitous, particularly in newer forms of writing such as social media. Fortunately, variation is not random; it is often linked to social properties of the author. In this paper, we show how to exploit social networks to make sentiment analysis more robust to social language variation. The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways. We formalize this idea in a novel attention-based neural network architecture, in which attention is divided among several basis models, depending on the author's position in the social network. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. This model significantly improves the accuracies of sentiment analysis on Twitter and review data.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1024/245</href>
    <pages>295--307</pages>
    <url>http://www.aclweb.org/anthology/Q17-1021</url>
  </paper>

  <paper id='1022'>
    <title>Semantic Specialization of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints</title>
    <author><first>Nikola</first><last>Mrkšić</last></author>
    <author><first>Ivan</first><last>Vulić</last></author>
    <author><first>Diarmuid Ó</first><last>Séaghdha</last></author>
    <author><first>Ira</first><last>Leviant</last></author>
    <author><first>Roi</first><last>Reichart</last></author>
    <author><first>Milica</first><last>Gašić</last></author>
    <author><first>Anna</first><last>Korhonen</last></author>
    <author><first>Steve</first><last>Young</last></author>
    <year>2017</year>
    <abstract>We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialized vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1171/246</href>
    <pages>309--324</pages>
    <url>http://www.aclweb.org/anthology/Q17-1022</url>
  </paper>

  <paper id='1023'>
    <title>Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding</title>
    <author><first>Will</first><last>Monroe</last></author>
    <author><first>Robert X. D.</first><last>Hawkins</last></author>
    <author><first>Noah D.</first><last>Goodman</last></author>
    <author><first>Christopher</first><last>Potts</last></author>
    <year>2017</year>
    <abstract>We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1142/247</href>
    <pages>325--338</pages>
    <url>http://www.aclweb.org/anthology/Q17-1023</url>
  </paper>

  <paper id='1024'>
    <title>Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</title>
    <author><first>Melvin</first><last>Johnson</last></author>
    <author><first>Mike</first><last>Schuster</last></author>
    <author><first>Quoc V.</first><last>Le</last></author>
    <author><first>Maxim</first><last>Krikun</last></author>
    <author><first>Yonghui</first><last>Wu</last></author>
    <author><first>Zhifeng</first><last>Chen</last></author>
    <author><first>Nikhil</first><last>Thorat</last></author>
    <author><first> Fernanda</first><last>Viégas</last></author>
    <author><first>Martin</first><last>Wattenberg</last></author>
    <author><first>Greg</first><last>Corrado</last></author>
    <author><first>Macduff</first><last>Hughes</last></author>
    <author><first>Jeffrey</first><last>Dean</last></author>
    <year>2017</year>
    <abstract>We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT using a single model. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-the-art results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT’14 and WMT’15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and show some interesting examples when mixing languages.</abstract>
    <href>https://transacl.org/ojs/index.php/tacl/article/download/1081/248</href>
    <pages>339--351</pages>
    <url>http://www.aclweb.org/anthology/Q17-1024</url>
  </paper>

</volume>
