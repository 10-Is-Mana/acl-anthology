<volume id='J16'>

  <paper id='1000'>
    <title>Computational Linguistics, Volume 43, Issue 1 - April 2017</title>
    <month>April</month>
    <year>2017</year>
  </paper>

  <paper id='1001'>
    <title>A Statistical, Grammar-Based Approach to Microplanning   </title>
    <author><first>Claire</first><last>Gardent</last></author>
    <author><first>Laura</first><last>Perez-Beltrachini</last></author>
    <month>April</month>
    <year>2017</year>
    <abstract>Although there has been much work in recent years on data-driven natural language generation, little attention has been paid to the fine-grained interactions that arise during microplanning between aggregation, surface realization, and sentence segmentation. In this article, we propose a hybrid symbolic/statistical approach to jointly model the constraints regulating these interactions. Our approach integrates a small handwritten grammar, a statistical hypertagger, and a surface realization algorithm. It is applied to the verbalization of knowledge base queries and tested on 13 knowledge bases to demonstrate domain independence. We evaluate our approach in several ways. A quantitative analysis shows that the hybrid approach outperforms a purely symbolic approach in terms of both speed and coverage. Results from a human study indicate that users find the output of this hybrid statistic/symbolic system more fluent than both a template-based and a purely symbolic grammar-based approach. Finally, we illustrate by means of examples that our approach can account for various factors impacting aggregation, sentence segmentation, and surface realization.</abstract>
    <pages>1-30</pages>
    <doi>10.1162/COLI_a_00273</doi>
    <url>http://www.aclweb.org/anthology/J17-1001</url>
  </paper>

  <paper id='1002'>
    <title>A Game-Theoretic Approach to Word Sense Disambiguation</title>
    <author><first>Rocco</first><last>Tripodi</last></author>
    <author><first>Marcello</first><last>Pelillo</last></author>
    <month>April</month>
    <year>2017</year>
    <abstract>This article presents a new model for word sense disambiguation formulated in terms of evolutionary game theory, where each word to be disambiguated is represented as a node on a graph whose edges represent word relations and senses are represented as classes. The words simultaneously update their class membership preferences according to the senses that neighboring words are likely to choose. We use distributional information to weigh the influence that each word has on the decisions of the others and semantic similarity information to measure the strength of compatibility among the choices. With this information we can formulate the word sense disambiguation problem as a constraint satisfaction problem and solve it using tools derived from game theory, maintaining the textual coherence. The model is based on two ideas: Similar words should be assigned to similar classes and the meaning of a word does not depend on all the words in a text but just on some of them. The article provides an in-depth motivation of the idea of modeling the word sense disambiguation problem in terms of game theory, which is illustrated by an example. The conclusion presents an extensive analysis on the combination of similarity measures to use in the framework and a comparison with state-of-the-art systems. The results show that our model outperforms state-of-the-art algorithms and can be applied to different tasks and in different scenarios.</abstract>
    <pages>31-70</pages>
    <doi>10.1162/COLI_a_00242</doi>
    <url>http://www.aclweb.org/anthology/J17-1002</url>
  </paper>

  <paper id='1003'>
    <title>Multilingual Metaphor Processing: Experiments with Semi-Supervised and Unsupervised Learning</title>
    <author><first>Ekaterina</first><last>Shutova</last></author>
    <author><first>Lin</first><last>Sun</last></author>
    <author><first>Elkin</first><last>Darío Gutiérrez</last></author>
    <author><first>Patricia</first><last>Lichtenstein</last></author>
    <author><first>Srini</first><last>Narayanan</last></author>
    <month>April</month>
    <year>2017</year>
    <abstract>Highly frequent in language and communication, metaphor represents a significant challenge for Natural Language Processing (NLP) applications. Computational work on metaphor has traditionally evolved around the use of hand-coded knowledge, making the systems hard to scale. Recent years have witnessed a rise in statistical approaches to metaphor processing. However, these approaches often require extensive human annotation effort and are predominantly evaluated within a limited domain. In contrast, we experiment with weakly supervised and unsupervised techniques—with little or no annotation—to generalize higher-level mechanisms of metaphor from distributional properties of concepts. We investigate different levels and types of supervision (learning from linguistic examples vs. learning from a given set of metaphorical mappings vs. learning without annotation) in flat and hierarchical, unconstrained and constrained clustering settings. Our aim is to identify the optimal type of supervision for a learning algorithm that discovers patterns of metaphorical association from text. In order to investigate the scalability and adaptability of our models, we applied them to data in three languages from different language groups—English, Spanish, and Russian—achieving state-of-the-art results with little supervision. Finally, we demonstrate that statistical methods can facilitate and scale up cross-linguistic research on metaphor.</abstract>
    <pages>71-123</pages>
    <doi>10.1162/COLI_a_00275</doi>
    <url>http://www.aclweb.org/anthology/J17-1003</url>
  </paper>

  <paper id='1004'>
    <title>Argumentation Mining in User-Generated Web Discourse</title>
    <author><first>Ivan</first><last>Habernal</last></author>
    <author><first>Iryna</first><last>Gurevych</last></author>
    <month>April</month>
    <year>2017</year>
    <abstract>The goal of argumentation mining, an evolving research field in computational linguistics, is to design methods capable of analyzing people's argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the data, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task.</abstract>
    <pages>125-179</pages>
    <doi>10.1162/COLI_a_00276</doi>
    <url>http://www.aclweb.org/anthology/J17-1004</url>
  </paper>

  <paper id='1005'>
    <title>Hashtag Sense Clustering Based on Temporal Similarity</title>
    <author><first>Giovanni</first><last>Stilo</last></author>
    <author><first>Paola</first><last>Velardi</last></author>
    <month>April</month>
    <year>2017</year>
    <abstract>Hashtags are creative labels used in micro-blogs to characterize the topic of a message/discussion. Regardless of the use for which they were originally intended, hashtags cannot be used as a means to cluster messages with similar content. First, because hashtags are created in a spontaneous and highly dynamic way by users in multiple languages, the same topic can be associated with different hashtags, and conversely, the same hashtag may refer to different topics in different time periods. Second, contrary to common words, hashtag disambiguation is complicated by the fact that no sense catalogs (e.g., Wikipedia or WordNet) are available; and, furthermore, hashtag labels are difficult to analyze, as they often consist of acronyms, concatenated words, and so forth. A common way to determine the meaning of hashtags has been to analyze their context, but, as we have just pointed out, hashtags can have multiple and variable meanings. In this article, we propose a temporal sense clustering algorithm based on the idea that semantically related hashtags have similar and synchronous usage patterns.</abstract>
    <pages>181-200</pages>
    <doi>10.1162/COLI_a_00277</doi>
    <url>http://www.aclweb.org/anthology/J17-1005</url>
  </paper>

  <paper id='1006'>
    <title>Evaluative Language Beyond Bags of Words: Linguistic Insights and Computational Applications   </title>
    <author><first>Farah</first><last>Benamara</last></author>
Maite Taboada
Yannick Mathieu
    <month>April</month>
    <year>2017</year>
    <abstract>The study of evaluation, affect, and subjectivity is a multidisciplinary enterprise, including sociology, psychology, economics, linguistics, and computer science. A number of excellent computational linguistics and linguistic surveys of the field exist. Most surveys, however, do not bring the two disciplines together to show how methods from linguistics can benefit computational sentiment analysis systems. In this survey, we show how incorporating linguistic insights, discourse information, and other contextual phenomena, in combination with the statistical exploitation of data, can result in an improvement over approaches that take advantage of only one of these perspectives. We first provide a comprehensive introduction to evaluative language from both a linguistic and computational perspective. We then argue that the standard computational definition of the concept of evaluative language neglects the dynamic nature of evaluation, in which the interpretation of a given evaluation depends on linguistic and extra-linguistic contextual factors. We thus propose a dynamic definition that incorporates update functions. The update functions allow for different contextual aspects to be incorporated into the calculation of sentiment for evaluative words or expressions, and can be applied at all levels of discourse. We explore each level and highlight which linguistic aspects contribute to accurate extraction of sentiment. We end the review by outlining what we believe the future directions of sentiment analysis are, and the role that discourse and contextual information need to play.</abstract>
    <pages>201-264</pages>
    <doi>10.1162/COLI_a_00278</doi>
    <url>http://www.aclweb.org/anthology/J17-1006</url>
  </paper>

  <paper id='1007'>
    <title>Book Review: Biomedical Natural Language Processing by Kevin Bretonnel Cohen and Dina Demner-Fushman</title>
    <author><first>Jin-Dong</first><last>Kim</last></author>
    <month>April</month>
    <year>2017</year>
    <pages>265-267</pages>
    <doi>10.1162/COLI_r_00281</doi>
    <url>http://www.aclweb.org/anthology/J17-1007</url>
  </paper>

  <paper id='1008'>
    <title>Book Review: Automatic Detection of Verbal Deception by Eileen Fitzpatrick, Joan Bachenko and Tommaso Fornaciari</title>
    <author><first>Yoong</first><last>Keok Lee</last></author>
    <month>April</month>
    <year>2017</year>
    <pages>269-271</pages>
    <doi>10.1162/COLI_r_00282</doi>
    <url>http://www.aclweb.org/anthology/J17-1008</url>
  </paper>


</volume>
