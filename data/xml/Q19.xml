<?xml version='1.0' encoding='UTF-8'?>
<volume id="Q19">
  <paper id="1000">
    <title>Transactions of the Association for Computational Linguistics, Volume 7</title>
    <year>2019</year>
  </paper>

  <paper id="1001">
    <title>Grammar Error Correction in Morphologically Rich Languages: The Case of Russian</title>
    <author><first>Alla</first><last>Rozovskaya</last></author>
    <author><first>Dan</first><last>Roth</last></author>
    <year>2019</year>
    <month>March</month>
    <doi>10.1162/tacl_a_00251</doi>
    <abstract>Until now, most of the research in grammar error correction focused on English, and the problem has hardly been explored for other languages. We address the task of correcting writing mistakes in morphologically rich languages, with a focus on Russian. We present a corrected and error-tagged corpus of Russian learner writing and develop models that make use of existing state-of-the-art methods that have been well studied for English. Although impressive results have recently been achieved for grammar error correction of non-native English writing, these results are limited to domains where plentiful training data are available. Because annotation is extremely costly, these approaches are not suitable for the majority of domains and languages. We thus focus on methods that use “minimal supervision”; that is, those that do not rely on large amounts of annotated training data, and show how existing minimal-supervision approaches extend to a highly inflectional language such as Russian. The results demonstrate that these methods are particularly useful for correcting mistakes in grammatical phenomena that involve rich morphology.</abstract>
    <pages>1–17</pages>
    <url>https://www.aclweb.org/anthology/Q19-1001</url>
  </paper>

  <paper id="1002">
    <title>Semantic Neural Machine Translation Using AMR</title>
    <author><first>Linfeng</first><last>Song</last></author>
    <author><first>Daniel</first><last>Gildea</last></author>
    <author><first>Yue</first><last>Zhang</last></author>
    <author><first>Zhiguo</first><last>Wang</last></author>
    <author><first>Jinsong</first><last>Su</last></author>
    <year>2019</year>
    <month>March</month>
    <doi>10.1162/tacl_a_00252</doi>
    <abstract>It is intuitive that semantic representations can be useful for machine translation, mainly because they can help in enforcing meaning preservation and handling data sparsity (many sentences correspond to one meaning) of machine translation models. On the other hand, little work has been done on leveraging semantics for neural machine translation (NMT). In this work, we study the usefulness of AMR (abstract meaning representation) on NMT. Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.</abstract>
    <pages>19–31</pages>
    <url>https://www.aclweb.org/anthology/Q19-1002</url>
  </paper>

  <paper id="1003">
    <title>Joint Transition-Based Models for Morpho-Syntactic Parsing: Parsing Strategies for MRLs and a Case Study from Modern Hebrew</title>
    <author><first>Amir</first><last>More</last></author>
    <author><first>Amit</first><last>Seker</last></author>
    <author><first>Victoria</first><last>Basmova</last></author>
    <author><first>Reut</first><last>Tsarfaty</last></author>
    <year>2019</year>
    <month>March</month>
    <doi>10.1162/tacl_a_00253</doi>
    <abstract>In standard NLP pipelines, morphological analysis and disambiguation (MA&amp;D) precedes syntactic and semantic downstream tasks. However, for languages with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that syntactic context may be crucial for accurate MA&amp;D, and vice versa. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference. We empirically show that MA&amp;D results obtained in the joint settings outperform MA&amp;D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.</abstract>
    <pages>33–48</pages>
    <url>https://www.aclweb.org/anthology/Q19-1003</url>
  </paper>

  <paper id="1004">
    <title>Analysis Methods in Neural Language Processing: A Survey</title>
    <author><first>Yonatan</first><last>Belinkov</last></author>
    <author><first>James</first><last>Glass</last></author>
    <year>2019</year>
    <month>April</month>
    <doi>10.1162/tacl_a_00254</doi>
    <abstract>The field of natural language processing has seen impressive progress in recent years, with neural network models replacing many of the traditional systems. A plethora of new models have been proposed, many of which are thought to be opaque compared to their feature-rich counterparts. This has led researchers to analyze, interpret, and evaluate neural networks in novel and more fine-grained ways. In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work.</abstract>
    <pages>49–72</pages>
    <url>https://www.aclweb.org/anthology/Q19-1004</url>
  </paper>
</volume>
